{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Resampling Methods",
      "provenance": [],
      "authorship_tag": "ABX9TyNAo+J6xeuoj9Bz13ZYQmmN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lauracline/Technical-Specs-of-Automobiles/blob/master/Resampling_Methods.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CL1NVF2kYIp"
      },
      "source": [
        "# **Resampling Methods**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctszSWqDkdow"
      },
      "source": [
        "## **Cross Validation**\n",
        "\n",
        "Usually a test set is not avaliable so a simple strategy to create one is to split the avaliable data into training and testing (validation set). For quanitative responses, usually use MSE, for categorical can use error rate, area under the curve, F1 score, weighting of confusion matrix, etc.\n",
        "\n",
        "## **Leave One Out Cross Validation**\n",
        "\n",
        "LOOCV has only one observation in the test set and uses all other n-1 observations to build a model. n different models are built leaving out eac observation once and error is averaged over these n trials. LOOCV is better than the simple method above. The model is built on nearly all the data and there is no randomness in the splits since each observation will be left out once. It is computationally expensive especially with large n and a complex model. \n",
        "\n",
        "## **K-Fold Cross Validation**\n",
        "\n",
        "Similiar to LOOCV, but this time you leave some number greater than 1 out. Here, k is the number of partitions of your sample, so if you have 1000 observations and k = 10, then each fold will be 100. These 100 observations would act as your test set. Get an MSE for each fold of these 100 observations and take the average. LOOCV is a special case of k-fold CV whenever k equals the number of observations. \n",
        "\n",
        "## **Bias-Variance Tradeoff Between LOOCV and K-Folds**\n",
        "\n",
        "Since LOOCV trains on nearly all the data, the test error rate will generally be lower than k-fold and therefore less biased. LOOCV will have higher vaariance since all n models will be very highly correlated to one another. Since the models won't differ much, the test error rate (which the CV is measuring) will vary more than k-fold which has fewer models that are less correlated with one another. A value of k between 5 and 10 is a good rule of thumb that balances the trade-off between bias and variance. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8HiiSnpkSMG"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSmBkgSUmFWE"
      },
      "source": [
        "## Applied Excercises \n",
        "\n",
        "1. In chapter 4, we used logistic regression to predict the probability of `default` using `income` and `balance` on the `Default` dataset. We will now estimate the test error of this logistic regression model using the validation set approach. \n",
        "\n",
        "a. Fit a logistic regression model that uses `income` and `balance` to predict `default`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFnMzhy5mijt"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhapvEH-mqjo"
      },
      "source": [
        "default = pd.read_csv('https://raw.githubusercontent.com/emredjan/ISL-python/master/datasets/Default.csv')\n",
        "default['student_yes'] = (default['student'] == 'Yes').astype('int')\n",
        "default['default_yes'] = (default['default'] == 'Yes').astype('int')"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "eSrBq5oenZLp",
        "outputId": "24709e02-bb25-47ed-a0f1-548e0114939a"
      },
      "source": [
        "default.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>default</th>\n",
              "      <th>student</th>\n",
              "      <th>balance</th>\n",
              "      <th>income</th>\n",
              "      <th>student_yes</th>\n",
              "      <th>default_yes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>729.526495</td>\n",
              "      <td>44361.625074</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>817.180407</td>\n",
              "      <td>12106.134700</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>1073.549164</td>\n",
              "      <td>31767.138947</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>529.250605</td>\n",
              "      <td>35704.493935</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>785.655883</td>\n",
              "      <td>38463.495879</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0 default student  ...        income  student_yes  default_yes\n",
              "0           1      No      No  ...  44361.625074            0            0\n",
              "1           2      No     Yes  ...  12106.134700            1            0\n",
              "2           3      No      No  ...  31767.138947            0            0\n",
              "3           4      No      No  ...  35704.493935            0            0\n",
              "4           5      No      No  ...  38463.495879            0            0\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wya5UUIlnctd"
      },
      "source": [
        "X = default[['balance', 'income']]\n",
        "y = default['default_yes']"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYxaaSCvniKo"
      },
      "source": [
        "No validation set\n",
        "\n",
        "Using sklearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9g3n4w8nh3u",
        "outputId": "49915bbd-8478-47c5-f47c-e3fb4b4d101b"
      },
      "source": [
        "# Notice how tol must be changed to less than default value or \n",
        "# convergence won't happen\n",
        "# Use a high value of C to remove regularization \n",
        "\n",
        "model = LogisticRegression(C=100000, tol=.0000001)\n",
        "model.fit(X,y)\n",
        "model.intercept_, model.coef_"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([-11.54046839]), array([[5.64710291e-03, 2.08089921e-05]]))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNjv3Vbsn9sN"
      },
      "source": [
        "Statsmodels \n",
        "\n",
        "Coefficients are similiar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0BJgSbuoBc_"
      },
      "source": [
        "import statsmodels.formula.api as smf"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhyqv-nPoFTH",
        "outputId": "6c5863dd-09ec-43d9-d640-b6c4f03521b5"
      },
      "source": [
        "result = smf.logit(formula = 'default_yes ~ balance + income', data=default).fit()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimization terminated successfully.\n",
            "         Current function value: 0.078948\n",
            "         Iterations 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "WSvBFlmLoObo",
        "outputId": "6dbc1f06-9f7a-478f-ac83-69a3c2cacf7b"
      },
      "source": [
        "result.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>Logit Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>      <td>default_yes</td>   <th>  No. Observations:  </th>   <td> 10000</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>   <td>  9997</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>   <td>     2</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>            <td>Sun, 05 Sep 2021</td> <th>  Pseudo R-squ.:     </th>   <td>0.4594</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                <td>15:43:27</td>     <th>  Log-Likelihood:    </th>  <td> -789.48</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th>  <td> -1460.3</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>4.541e-292</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Intercept</th> <td>  -11.5405</td> <td>    0.435</td> <td>  -26.544</td> <td> 0.000</td> <td>  -12.393</td> <td>  -10.688</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>balance</th>   <td>    0.0056</td> <td>    0.000</td> <td>   24.835</td> <td> 0.000</td> <td>    0.005</td> <td>    0.006</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>income</th>    <td> 2.081e-05</td> <td> 4.99e-06</td> <td>    4.174</td> <td> 0.000</td> <td>  1.1e-05</td> <td> 3.06e-05</td>\n",
              "</tr>\n",
              "</table><br/><br/>Possibly complete quasi-separation: A fraction 0.14 of observations can be<br/>perfectly predicted. This might indicate that there is complete<br/>quasi-separation. In this case some parameters will not be identified."
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                           Logit Regression Results                           \n",
              "==============================================================================\n",
              "Dep. Variable:            default_yes   No. Observations:                10000\n",
              "Model:                          Logit   Df Residuals:                     9997\n",
              "Method:                           MLE   Df Model:                            2\n",
              "Date:                Sun, 05 Sep 2021   Pseudo R-squ.:                  0.4594\n",
              "Time:                        15:43:27   Log-Likelihood:                -789.48\n",
              "converged:                       True   LL-Null:                       -1460.3\n",
              "Covariance Type:            nonrobust   LLR p-value:                4.541e-292\n",
              "==============================================================================\n",
              "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------\n",
              "Intercept    -11.5405      0.435    -26.544      0.000     -12.393     -10.688\n",
              "balance        0.0056      0.000     24.835      0.000       0.005       0.006\n",
              "income      2.081e-05   4.99e-06      4.174      0.000     1.1e-05    3.06e-05\n",
              "==============================================================================\n",
              "\n",
              "Possibly complete quasi-separation: A fraction 0.14 of observations can be\n",
              "perfectly predicted. This might indicate that there is complete\n",
              "quasi-separation. In this case some parameters will not be identified.\n",
              "\"\"\""
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yO4HJKr2oTvl"
      },
      "source": [
        "Error without validation set\n",
        "\n",
        "This is an in-sample prediction. Training error in both sklearn and statsmodels. Both are equivalent. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHO8mnwNoZaU",
        "outputId": "9df0f178-8de9-4d2b-a9cd-b5b9d04cd4b6"
      },
      "source": [
        "(model.predict(X) == y).mean()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9737"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaeJMRbUodO6",
        "outputId": "14c5618d-c0ea-4cde-9602-44987e95302f"
      },
      "source": [
        "((result.predict(X) > .5)*1 == y).mean()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9737"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLM4XRhcop7l"
      },
      "source": [
        "b. Using the validation set approach, estimate the test error of this model. In order to do this, you must perform the following steps:\n",
        "\n",
        "i. Split the sample set into a training set and a validation set. \n",
        "\n",
        "ii. Fit a multiple logistic regression model using only the training observations. \n",
        "\n",
        "iii. Obtain a prediction of default status for each individual in the validation set by computing the posterior probability of default for that individual, and classifying the individual to the `default` category if the posterior probability is greater than 0.5. \n",
        "\n",
        "iv. Compute the validation set error, which is the fraction of the observations in the validation set that are misclassified. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SG2HM91pKWV"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5n5mlMnpP1V",
        "outputId": "1bca2767-c7e6-4893-8e6e-cdb38f29e327"
      },
      "source": [
        "model = LogisticRegression(C=100000, tol=0.0000001)\n",
        "model.fit(X_train, y_train)\n",
        "model.intercept_, model.coef_"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([-11.51405382]), array([[5.60596598e-03, 2.22188422e-05]]))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEjxeROqpZSm"
      },
      "source": [
        "X_train_sm = X_train.join(y_train)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "u9OxHE1NpdJe",
        "outputId": "b8c5af4a-cb2d-4770-8e1a-374aa12bc99b"
      },
      "source": [
        "result = smf.logit(formula = 'default_yes ~ balance + income', data=X_train_sm).fit()\n",
        "result.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimization terminated successfully.\n",
            "         Current function value: 0.080650\n",
            "         Iterations 10\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>Logit Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>      <td>default_yes</td>   <th>  No. Observations:  </th>   <td>  7500</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>   <td>  7497</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>   <td>     2</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>            <td>Sun, 05 Sep 2021</td> <th>  Pseudo R-squ.:     </th>   <td>0.4581</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                <td>15:49:20</td>     <th>  Log-Likelihood:    </th>  <td> -604.87</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th>  <td> -1116.2</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>8.459e-223</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Intercept</th> <td>  -11.5141</td> <td>    0.495</td> <td>  -23.260</td> <td> 0.000</td> <td>  -12.484</td> <td>  -10.544</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>balance</th>   <td>    0.0056</td> <td>    0.000</td> <td>   21.764</td> <td> 0.000</td> <td>    0.005</td> <td>    0.006</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>income</th>    <td> 2.222e-05</td> <td>  5.7e-06</td> <td>    3.897</td> <td> 0.000</td> <td>  1.1e-05</td> <td> 3.34e-05</td>\n",
              "</tr>\n",
              "</table><br/><br/>Possibly complete quasi-separation: A fraction 0.13 of observations can be<br/>perfectly predicted. This might indicate that there is complete<br/>quasi-separation. In this case some parameters will not be identified."
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                           Logit Regression Results                           \n",
              "==============================================================================\n",
              "Dep. Variable:            default_yes   No. Observations:                 7500\n",
              "Model:                          Logit   Df Residuals:                     7497\n",
              "Method:                           MLE   Df Model:                            2\n",
              "Date:                Sun, 05 Sep 2021   Pseudo R-squ.:                  0.4581\n",
              "Time:                        15:49:20   Log-Likelihood:                -604.87\n",
              "converged:                       True   LL-Null:                       -1116.2\n",
              "Covariance Type:            nonrobust   LLR p-value:                8.459e-223\n",
              "==============================================================================\n",
              "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------\n",
              "Intercept    -11.5141      0.495    -23.260      0.000     -12.484     -10.544\n",
              "balance        0.0056      0.000     21.764      0.000       0.005       0.006\n",
              "income      2.222e-05    5.7e-06      3.897      0.000     1.1e-05    3.34e-05\n",
              "==============================================================================\n",
              "\n",
              "Possibly complete quasi-separation: A fraction 0.13 of observations can be\n",
              "perfectly predicted. This might indicate that there is complete\n",
              "quasi-separation. In this case some parameters will not be identified.\n",
              "\"\"\""
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZMPh-dXpp-f",
        "outputId": "c5e32a1c-1f38-4544-c864-5ed151b3e792"
      },
      "source": [
        "# Nearly the same as the training set. So not too much over fitting \n",
        "# has happened\n",
        "(model.predict(X_test) == y_test).mean(), ((result.predict(X_test) > 0.5)*1 == y_test).mean()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9752, 0.9752)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hf58wO0p5Fu"
      },
      "source": [
        "Validation error is only 0.272. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnDSbiDEp-Cb"
      },
      "source": [
        "c. Repeat the process in (b) three times, using three different splits of the observations into a training set and a validation set. Comment on the results obtained. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jn4xFosEqGjB",
        "outputId": "19c27264-df30-44a1-c771-b6836f28d38a"
      },
      "source": [
        "model = LogisticRegression(C=100000, tol=.0000001)\n",
        "\n",
        "for i in range(3):\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X,y)\n",
        "  model.fit(X_train, y_train)\n",
        "\n",
        "  X_train_sm = X_train.join(y_train)\n",
        "  result = smf.logit(formula='default_yes ~ balance + income', data=X_train_sm).fit()\n",
        "  print((model.predict(X_test) == y_test).mean(), ((result.predict(X_test) > 0.5)*1 == y_test).mean())"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimization terminated successfully.\n",
            "         Current function value: 0.077908\n",
            "         Iterations 10\n",
            "0.9712 0.9712\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.082171\n",
            "         Iterations 10\n",
            "0.972 0.9808\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.080580\n",
            "         Iterations 10\n",
            "0.9672 0.9728\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHqwLWMGqtdY"
      },
      "source": [
        "d. Now consider a logistic regression model that predicts the probability of `default` using `income`, `balance`, and a dummy variable for `student`. Estimate the test error for this model using the validation set approach. Comment on whether or not including a dummy variable for `student` leads to a reduction in the test error rate. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "paInt_A1rlGa",
        "outputId": "c8de0133-e919-43e8-80b9-b99545bce258"
      },
      "source": [
        "X = default[['balance', 'income', 'student_yes']]\n",
        "y = default['default_yes']\n",
        "\n",
        "model = LogisticRegression(C=100000, tol=.0000001)\n",
        "\n",
        "for i in range(3):\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X,y)\n",
        "  model.fit(X_train, y_train)\n",
        "\n",
        "  X_train_sm = X_train.join(y_train)\n",
        "  result = smf.logit(formula='default_yes ~ balance + income + student_yes', data = X_train_sm).fit()\n",
        "  print((model.predict(X_test) == y_test).mean(), ((result.predict(X_test) > 0.5)*1 == y_test).mean())"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimization terminated successfully.\n",
            "         Current function value: 0.081403\n",
            "         Iterations 10\n",
            "0.972 0.9768\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.080568\n",
            "         Iterations 10\n",
            "0.9676 0.974\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.078957\n",
            "         Iterations 10\n",
            "0.9668 0.9728\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFv7hs3Os58P"
      },
      "source": [
        "Looks like the error rate is very similiar. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EticJGuGs8bF"
      },
      "source": [
        "2. We continue to consider the use of logistic regression model to predict the probability of `default` using `income` and `balance` on the `Default` dataset. In particular, we will now compute estimates for the standard errors of the `income` and `balance` logistic regression coefficients using two different ways: (1) using the bootstrap, and (2) using the standard formula for computing the standard errors in the logistic regression function. "
      ]
    }
  ]
}