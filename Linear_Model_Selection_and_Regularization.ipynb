{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Linear Model Selection and Regularization",
      "provenance": [],
      "authorship_tag": "ABX9TyP/wFqahh0E632ea1yWgDJe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lauracline/Technical-Specs-of-Automobiles/blob/master/Linear_Model_Selection_and_Regularization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-CpP3TDmqBV"
      },
      "source": [
        "# **Chapter Six: Linear Model Selection and Regularization** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gwbN0SImzpM"
      },
      "source": [
        "Linear models still do astonishinlgy well compared to non-linear modles. This chapter will explore other types of fitting besides least squares because they can given better prediction accuracy and interpretability. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCe7h3Fpm9EZ"
      },
      "source": [
        "## **Classes of Alternatives to Least Squares**\n",
        "\n",
        "1. Subset Selection: Choose of a subset of the predictors\n",
        "2. Shrinkage (Regularization): Fit all predictors but limit their size. Coefficients can go to 0. \n",
        "3. Dimension Reduction: project the predictors into a smaller subspace. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erUXH2ZgnNQX"
      },
      "source": [
        "## **Best Subset Selection**\n",
        "\n",
        "Fit all the possible models $2^{p}$ and take the one with the highest adjusted $R^{2}$ through cross validation. This can be impossible with a large enough p. \n",
        "\n",
        "## **Stepwise Selection - Forward, Backward and Both**\n",
        "\n",
        "Because of computational limitation a simpler method of adding or subtracting the best predictor to the current model is employed. \n",
        "\n",
        "### **Forward Selection**\n",
        "\n",
        "Start with an empty model and choose a predictor to add to the model based on the best adjusted $R^{2}$ or other similiar metric. Continue adding variables until no improvement in adjusted $R^{2}$. \n",
        "\n",
        "A variation of this is to retain each model at each step and use $R^{2}$ (not adjusted) as the metric. This will build p models. Then use cross validation witth $R^{2}$ to pick the best model of those p models built from forward selection. \n",
        "\n",
        "### **Backward Selection**\n",
        "\n",
        "Similiar to forward selection but start with all predictors in the model and remove one at a time until adjusted $R^{2}$ is maximized or alternatively, find p models with $R^{2}$ and then use cross validation to pick the best of the p models. \n",
        "\n",
        "### **Both**\n",
        "\n",
        "At each step, consider both adding or subtracting a variable in the model. \n",
        "\n",
        "## **Choosing Optimal Model**\n",
        "\n",
        "### **Adjusting Training Statistics or Using Cross Validation** \n",
        "\n",
        "As learned in Chapter 5, cross validation is an extremely good tool at giving us insight to how well the model will be used on unseen data (test data). \n",
        "\n",
        "But alternatively to cross validation, we can punish the training error statistics so in theory they can give us insight on what the test error will be. There have been several statistics developed to give us insight as to what the model will do for unseen errors. \n",
        "\n",
        "The four most popular are AIC, BIC, Mallows Cp, and Adjusted $R^{2}$. AIC, BIC and Cp all have similiar formulas that inflate the error for more predictors and a higher estimated varaince. Adjusted $R^{2}$ lowers the $R^{2}$ by each additional predictor in the model. All four of these statistics are 'classical' model selectors and were used before cross validation and so relied on just fitting the data one time on ALL the data. \n",
        "\n",
        "Cross validation can be computationally intense but with modern computation we can build lots of models and evaluate them easily. \n",
        "\n",
        "### **Shrinkage Methods**\n",
        "\n",
        "Ridge and Lasso regression are the most common. \n",
        "\n",
        "#### **Ridge Regression**\n",
        "\n",
        "Minmimizes not only the squared error (RSS) but sum of predictors squared times a constant $\\lambda$. When $\\lambda$ is 0 then ridge equals least squares, when $\\lambda$ heads to infinity, all predictors head to 0. \n",
        "\n",
        "Since ridge regression works directly with the size of the parameter coefficients, you must scale all the predictors by dividing by their standard deviation. \n",
        "\n",
        "#### **The Lasso**\n",
        "\n",
        "Uses L1 penalty instead of L2 (absolute value of predictors vs. squared value). The lasso performs variable selection by setting some predictors exacly 0 (and thus automatic variable selection), unlike ridge which will never completely eliminate variables. \n",
        "\n",
        "#### **Alternative Logic of Lasso and Ridge Regression**\n",
        "\n",
        "Instead of thinking of penalizing the error by either the L1 or L2 norm, we can think of setting up lasso/ridge regression as minimizing the squared errors subject to keeping the parameters less than a certain value. Think of this value as a 'budget' of allowable spending to occur. You can allow yourself to spend your parameters in any way you chose as long as you don't go over the total budget. \n",
        "\n",
        "Lasso yields predictors equivalent to 0 because of sharp corners. \n",
        "\n",
        "#### **What is Better, Lasso or Ridge?**\n",
        "\n",
        "No way to tell beforehand in general, in settings where they are many important predictor variables that related to the response, ridge regression will perform better. When there are only a few variables related to the response, then lasso will do better. \n",
        "\n",
        "But...as always cross validation can be used. \n",
        "\n",
        "#### **Choosing Lambda**\n",
        "\n",
        "Choos $\\lambda$ through cross validation. Search an array of $\\lambda$'s through cross validation and choose the $\\lambda$ which minimizes MSE. Then build your model with that $\\lambda$ on all the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVC9wpxQqxOM"
      },
      "source": [
        "## **Dimension Reduction Techniques**\n",
        "\n",
        "Instead of using the origianl predictors, we transform then first and then fit our models. Usually we transform variables so that there are less in number than the original set. Two approaches are recommended - principal components and partial least squares. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVYn5aP9rEKk"
      },
      "source": [
        "### **Principal Component Analysis (PCA)**\n",
        "\n",
        "The first principal component is the direction where observations vary the most. We want to capture as much information as we can in one single direction. Which single direction captures as much information as possible? The direction where the variance is highest amongest the projected points. \n",
        "\n",
        "The first principal components also minimizes the sum of squared perpendicular distances between point and line. Each transformed first principal component can be thought as single number summaries of all that particular observation.\n",
        "\n",
        "The second principal component must be uncorrelated to the first which makes it orthogonal (90 degrees in two dimensions) to the first. The second principal component will capture less information (less spread). Plotting each principal component against each variable can show how much information is captured by each one. \n",
        "\n",
        "#### **Principal Component Regression**\n",
        "\n",
        "First find the first M principal components where M < p then fit with least squares. Choose M with cross validation. Usually, data is standardized by standard deviation first. \n",
        "\n",
        "#### **Partial Least Squares**\n",
        "\n",
        "The response does not determine the principal components. This means PCA is used in an unsupervised way. PLS is a supervised alternative to PCR. PLS generates new features as a linear combination of the old features and the response. \n",
        "\n",
        "Computed by doing simple linear regression of Y onto each predictor and setting that coefficient to the linear combination coefficient for transformed variable Z1. So weights are higher for those variables with stronger relationships to response. Z2 is computed by regressing all variables against the residuals of Z1 being fit to the model. Do this iteratively (fit remaining residuals) to come up with M PLS components. Then do least squares fit on all M new dimensions. In practice, PLS does not do better than PCR or ridge regression. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fqos2l-psuIq"
      },
      "source": [
        "## **High Dimensional Data**\n",
        "\n",
        "When speaking of high dimensional data, we generally mean data with many predictors, especially when p approaches or exceeds n. Generally it is better to have more predictors but if many of the predictors are not associated with the response then they can cause the actual signal to get diluted - a double edged sword these predictors. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8F7RPhGEs_p2"
      },
      "source": [
        "## **Excercises**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwsF9oYAtO7m"
      },
      "source": [
        "### **Question Eight**\n",
        "\n",
        "In this excercise, we will generate simulated data, and will then use this data to perform best subset selection. \n",
        "\n",
        "A. Use the random function to generate a predictor X of length n = 100 as well as a noise vector $\\epsilon$ of length n = 100. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5cD8PmTtmNq"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import Lasso\n",
        "import matplotlib as plt\n",
        "%matplotlib inline "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJjYCKs3tg5v"
      },
      "source": [
        "x = np.random.randn(100)\n",
        "err = np.random.randn(100)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luU0bGOPuaCC"
      },
      "source": [
        "B. Generate a response vector y of length n = 100 according to the model $Y = \\beta_{0} + \\beta_{1}X + \\beta_{2}X^{2} + \\beta_{3}X^{3} + \\epsilon$, where $\\beta_{0}$, $\\beta_{1}$, $\\beta_{2}$, and $\\beta_{3}$ are constants of your choice. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7WjvAsMuK3w"
      },
      "source": [
        "beta0, beta1, beta2, beta3 = -5, 1, 4, 3\n",
        "y = beta0 + beta1 * x + beta2 * x ** 2 + beta3 * x ** 3 + err"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkGvpqaXu49o"
      },
      "source": [
        "C. Perform best subset selection in order to choose the best model containing the predictors $X$, $X^{2}$,...,$X^{10}$. What is the best model obtained according to $C_{p}$, BIC, and adjusted $R^{2}$? Show some plots to provide evidence for your answer and report the coefficients of the best model obtained. You will also need to create a single dataset containing both X and y. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzdb7TS4vQ3A"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from itertools import combinations\n",
        "from collections import OrderedDict"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEINJNA1vcRy",
        "outputId": "0469e29a-0f77-4178-b174-a6790af75df1"
      },
      "source": [
        "OrderedDict({'b': 1, 'a':534})"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('b', 1), ('a', 534)])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZzH8P1Avi4R"
      },
      "source": [
        "df = pd.DataFrame({'x1': x, 'x2': x ** 2, 'x3': x**3, 'x4': x**4,'x5': x**5,\n",
        "                   'x6': x**6,'x7': x**7,'x8': x**8,'x9': x**9,'x9_10': x**10,\n",
        "                   'y':y})"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "SKy4BFz8vw-p",
        "outputId": "a6296842-1830-4b6b-81bb-2d8a6c29d34f"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x1</th>\n",
              "      <th>x2</th>\n",
              "      <th>x3</th>\n",
              "      <th>x4</th>\n",
              "      <th>x5</th>\n",
              "      <th>x6</th>\n",
              "      <th>x7</th>\n",
              "      <th>x8</th>\n",
              "      <th>x9</th>\n",
              "      <th>x9_10</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.136000</td>\n",
              "      <td>0.018496</td>\n",
              "      <td>-0.002515</td>\n",
              "      <td>0.000342</td>\n",
              "      <td>-0.000047</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>-8.605272e-07</td>\n",
              "      <td>1.170314e-07</td>\n",
              "      <td>-1.591623e-08</td>\n",
              "      <td>2.164602e-09</td>\n",
              "      <td>-6.497316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.246996</td>\n",
              "      <td>0.061007</td>\n",
              "      <td>-0.015068</td>\n",
              "      <td>0.003722</td>\n",
              "      <td>-0.000919</td>\n",
              "      <td>0.000227</td>\n",
              "      <td>-5.608246e-05</td>\n",
              "      <td>1.385213e-05</td>\n",
              "      <td>-3.421419e-06</td>\n",
              "      <td>8.450761e-07</td>\n",
              "      <td>-3.023842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.220629</td>\n",
              "      <td>0.048677</td>\n",
              "      <td>-0.010740</td>\n",
              "      <td>0.002369</td>\n",
              "      <td>-0.000523</td>\n",
              "      <td>0.000115</td>\n",
              "      <td>-2.544725e-05</td>\n",
              "      <td>5.614406e-06</td>\n",
              "      <td>-1.238702e-06</td>\n",
              "      <td>2.732938e-07</td>\n",
              "      <td>-6.139051</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.816383</td>\n",
              "      <td>0.666480</td>\n",
              "      <td>0.544103</td>\n",
              "      <td>0.444196</td>\n",
              "      <td>0.362634</td>\n",
              "      <td>0.296048</td>\n",
              "      <td>2.416884e-01</td>\n",
              "      <td>1.973102e-01</td>\n",
              "      <td>1.610806e-01</td>\n",
              "      <td>1.315034e-01</td>\n",
              "      <td>0.477312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.530012</td>\n",
              "      <td>0.280913</td>\n",
              "      <td>-0.148887</td>\n",
              "      <td>0.078912</td>\n",
              "      <td>-0.041824</td>\n",
              "      <td>0.022167</td>\n",
              "      <td>-1.174899e-02</td>\n",
              "      <td>6.227108e-03</td>\n",
              "      <td>-3.300442e-03</td>\n",
              "      <td>1.749274e-03</td>\n",
              "      <td>-5.609277</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         x1        x2        x3  ...            x9         x9_10         y\n",
              "0 -0.136000  0.018496 -0.002515  ... -1.591623e-08  2.164602e-09 -6.497316\n",
              "1 -0.246996  0.061007 -0.015068  ... -3.421419e-06  8.450761e-07 -3.023842\n",
              "2 -0.220629  0.048677 -0.010740  ... -1.238702e-06  2.732938e-07 -6.139051\n",
              "3  0.816383  0.666480  0.544103  ...  1.610806e-01  1.315034e-01  0.477312\n",
              "4 -0.530012  0.280913 -0.148887  ... -3.300442e-03  1.749274e-03 -5.609277\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZLNvO8ovyr6"
      },
      "source": [
        "lr = LinearRegression()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Dj5dHVSv0ld"
      },
      "source": [
        "X = df.iloc[:, :-1]\n",
        "y = df['y']"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEqU8_IJv9XK",
        "outputId": "ecb6dd5b-c77c-43ad-91f7-6c4449b8fb40"
      },
      "source": [
        "lr.fit(X,y)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-hcWm6Lv_GN"
      },
      "source": [
        "sigma2 = np.sum((lr.predict(X) - y) ** 2) / len(X)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "VX16UBuUwEkQ",
        "outputId": "6f714e78-d4b3-4ce9-92a3-33937bc08130"
      },
      "source": [
        "# Best subset selection \n",
        "n = len(X)\n",
        "idx = pd.IndexSlice\n",
        "cp = []\n",
        "bic = []\n",
        "adj_r2 = []\n",
        "for i in range(1, 11):\n",
        "    current_cp = []\n",
        "    current_bic = []\n",
        "    current_adj_r2 = []\n",
        "    for comb in combinations(range(10), i):\n",
        "        X = df.iloc[:,comb]\n",
        "        lr.fit(X, y)\n",
        "        rss = np.sum((lr.predict(X) - y) ** 2)\n",
        "        tss = np.sum((y - y.mean()) ** 2)\n",
        "        d = len(comb)\n",
        "        current_cp.append(1/n * (rss + 2 * d * sigma2))\n",
        "        current_bic.append(1/n * (rss + np.log(n) * d * sigma2))\n",
        "        current_adj_r2.append(1 - rss / (n - d - 1) * (n - 1) / tss)\n",
        "        \n",
        "    cp.append(min(current_cp))\n",
        "    bic.append(min(current_bic))\n",
        "    adj_r2.append(max(current_adj_r2))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexingError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexingError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-8b379dbeb520>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mcurrent_adj_r2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcomb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcomb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mrss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    871\u001b[0m                     \u001b[0;31m# AttributeError for IntervalTree get_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    874\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m             \u001b[0;31m# we by definition only have the 0th axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_valid_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1444\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_has_valid_tuple\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Too many indexers\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_key\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1354\u001b[0m             \u001b[0;31m# a tuple should already have been caught by this point\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m             \u001b[0;31m# so don't treat a tuple as a valid indexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Too many indexers\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_list_like_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m             \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexingError\u001b[0m: Too many indexers"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "id": "bIoSNH5XyDRR",
        "outputId": "8549aa07-7a26-4d74-a1bb-87d423bc9930"
      },
      "source": [
        "plt.figure(figsize=(10,8))\n",
        "plt.plot(range(1, 11), cp)\n",
        "plt.plot(range(1, 11), bic)\n",
        "plt.title(\"CP and BIC Best subset\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-b840b4fd8445>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CP and BIC Best subset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "nYj3pspwAdR3",
        "outputId": "c638c748-b838-41a6-adf1-9ef1d537bc1c"
      },
      "source": [
        "plt.figure(figsize=(10,8))\n",
        "plt.plot(range(1,11), adj_r2)\n",
        "plt.title(\"Adjusted R^2\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-1cf281c9cb53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj_r2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Adjusted R^2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "id": "9Z8TV1alBFD9",
        "outputId": "c6758afa-445b-4d69-d3ca-6235fb27fba0"
      },
      "source": [
        "# all three agree on the correct model\n",
        "np.argmin(cp), np.argmin(bic), np.argmin(adj_r2)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-1b985f4ab2c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# all three agree on the correct model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madj_r2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36margmin\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36margmin\u001b[0;34m(a, axis, out)\u001b[0m\n\u001b[1;32m   1267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m     \"\"\"\n\u001b[0;32m-> 1269\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'argmin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbound\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapit\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mwrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: attempt to get argmin of an empty sequence"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kccQVDfvQXl"
      },
      "source": [
        "D. Repeat (C), using forward stepwise selection and also using backwards stepwise selection. How does your answer compare to the results in (C)?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQu973HfBV_u"
      },
      "source": [
        "# Forward selection. Looks at Cp each step and stops \n",
        "# if it can't beat old best\n",
        "current_vars = []\n",
        "best_cp = 10000000\n",
        "prev_cp = best_cp\n",
        "best_cp = 1000000\n",
        "while best_cp < prev_cp:\n",
        "    prev_cp = best_cp\n",
        "    old_vars = current_vars.copy()\n",
        "    for i in range(10):\n",
        "        if i in current_vars:\n",
        "            continue\n",
        "        X = df.iloc[:, old_vars + [i]]\n",
        "        lr.fit(X, y)\n",
        "        rss = np.sum((lr.predict(X) - y) ** 2)\n",
        "        d = len(old_vars) + 1\n",
        "        cur_cp = 1/n * (rss + 2 * d * sigma2)\n",
        "        if cur_cp < best_cp:\n",
        "            current_vars = old_vars + [i]\n",
        "            best_cp = cur_cp"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-7jjGzmCPNt",
        "outputId": "c8096d55-3bab-4790-a9b1-5fbe8f9d32e2"
      },
      "source": [
        "current_vars"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 1, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0VmGzcVCQ1Y",
        "outputId": "2b1d36d8-bf89-4207-ede2-379e764aebac"
      },
      "source": [
        "best_cp"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.739982541615513"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YoSwfdyMCVYx",
        "outputId": "956038f9-fc55-44a6-c4f2-18248de98638"
      },
      "source": [
        "old_vars"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 1, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tb8iBZ4SCX1L"
      },
      "source": [
        "# Backward stepwise selection. Looks at Cp each steps and stops if it\n",
        "# can't beat the old best\n",
        "\n",
        "current_vars = list(range(10))\n",
        "best_cp = 10000000\n",
        "prev_cp = best_cp\n",
        "best_cp = 1000000\n",
        "while best_cp < prev_cp:\n",
        "    prev_cp = best_cp\n",
        "    old_vars = current_vars.copy()\n",
        "    for i in range(10):\n",
        "        if i not in current_vars:\n",
        "            continue\n",
        "        old_vars2 = old_vars.copy()\n",
        "        old_vars2.remove(i)\n",
        "        X = df.iloc[:, old_vars2]\n",
        "        lr.fit(X, y)\n",
        "        rss = np.sum((lr.predict(X) - y) ** 2)\n",
        "        d = len(old_vars) + 1\n",
        "        cur_cp = 1/n * (rss + 2 * d * sigma2)\n",
        "        if cur_cp < best_cp:\n",
        "            current_vars = old_vars2.copy()\n",
        "            best_cp = cur_cp"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWJm0CwgCfeN",
        "outputId": "44ca7502-58ca-408f-a429-2e80c6c744d6"
      },
      "source": [
        "current_vars # Different answer for backward selection "
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2, 5, 7, 9]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBll_l1KCr1m"
      },
      "source": [
        "E. Now fit a lasso model to the simulated data, again using $X$, $X^{2}$,...,$X^{10}$ as predictors. Use cross-validation to select the optimal value of $\\lambda$. Create plots of the cross-validation error as a function of $\\lambda$. Report the resulting coefficient estimates, and discuss the results obtained. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wV9LXudaDC9h"
      },
      "source": [
        "X = df.iloc[:, :-1]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SncHPvgRDGHC"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import Lasso"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YP0kHeQUDRYw"
      },
      "source": [
        "X_stand = X / X.std()"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VphhI_WdDUY2"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_stand, y)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBVYjOBED8UE"
      },
      "source": [
        "import matplotlib.pyplot as plt "
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "id": "qx5FdoNlDZoO",
        "outputId": "28807b58-d341-4f03-a855-bd55d94ab39b"
      },
      "source": [
        "alphas = np.linspace(.0001, .1, 1000)\n",
        "errors = []\n",
        "for alpha in alphas:\n",
        "    ls = Lasso(alpha, max_iter=100000, tol=.0001)\n",
        "    ls.fit(X_train, y_train)\n",
        "    errors.append(np.mean((ls.predict(X_test) - y_test) ** 2))\n",
        "\n",
        "plt.plot(alphas, errors)\n",
        "plt.show()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8807491597892678, tolerance: 0.582480488586456\n",
            "  positive)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69EjOkE6Dtof",
        "outputId": "45312b57-ca06-469e-af70-25eaed52d4de"
      },
      "source": [
        "np.argmin(errors)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "284"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qoPkcooSEJX1",
        "outputId": "985a1b83-6e3a-4dea-9bd9-25e97f9f2e16"
      },
      "source": [
        "alphas[53]"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0054"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZscvgHILELGC",
        "outputId": "7f31c1d9-6007-4360-d2e9-eaf0880be465"
      },
      "source": [
        "ls = Lasso(alpha = 0.0054, max_iter=100000, tol = 0.0001)\n",
        "ls.fit(X_stand, y)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Lasso(alpha=0.0054, copy_X=True, fit_intercept=True, max_iter=100000,\n",
              "      normalize=False, positive=False, precompute=False, random_state=None,\n",
              "      selection='cyclic', tol=0.0001, warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41eVQJJIETX4",
        "outputId": "c775eb40-1185-45d0-9efd-d3fc85f164ed"
      },
      "source": [
        "ls.intercept_, ls.coef_"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-4.897010252204153,\n",
              " array([ 1.09930815,  5.32858719, 10.79046387,  0.93354062, -0.        ,\n",
              "        -0.        , -0.        , -0.        , -0.02250285, -0.44600536]))"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlkdMJxqEWK2",
        "outputId": "f6523d5a-7958-406f-e9c4-ac9628b8a5f5"
      },
      "source": [
        "# beta 3 was very far off\n",
        "beta0, beta1, beta2, beta3"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-5, 1, 4, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJx1zQFfEdBO"
      },
      "source": [
        "F. Now generate a response vector $Y$ according to the model \n",
        "\n",
        "$Y = \\beta_{0} + \\beta_{7}X^{7} + \\epsilon$,\n",
        "\n",
        "and perform best subset selection and the lasso. Discuss the results obtained. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feW-w1BaEr9K"
      },
      "source": [
        "beta0_7 = 3\n",
        "beta7 = -1"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2ckj4u2Ev2r"
      },
      "source": [
        "y_7 = beta0_7 + beta7 * x ** 7 + err"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBmUAkiZE3Ab"
      },
      "source": [
        "df_7 = pd.DataFrame({'x1': x, 'x2': x ** 2, 'x3': x**3, 'x4': x**4,'x5': x**5,\n",
        "                   'x6': x**6,'x7': x**7,'x8': x**8,'x9': x**9,'x9_10': x**10,\n",
        "                   'y':y_7})"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "l01CjS99E5aG",
        "outputId": "439412bb-c849-4c09-85e6-0544cec484ce"
      },
      "source": [
        "plt.scatter(X['x7'], y_7)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f4e9b2ea2d0>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "Pq9UXf0aFCZc",
        "outputId": "1b294ecf-94fb-48d8-b74d-bebd2bac90d8"
      },
      "source": [
        "# Best subset selection \n",
        "\n",
        "\n",
        "# best subset selection\n",
        "X = df_7.iloc[:, :-1]\n",
        "n = len(X)\n",
        "tss = np.sum((y_7 - y_7.mean()) ** 2)\n",
        "lr.fit(X,  y_7)\n",
        "sigma2 = np.sum((lr.predict(X) - y_7) ** 2) / len(X)\n",
        "cp = []\n",
        "bic = []\n",
        "adj_r2 = []\n",
        "for i in range(1, 11):\n",
        "    current_cp = []\n",
        "    current_bic = []\n",
        "    current_adj_r2 = []\n",
        "    for comb in combinations(range(10), i):\n",
        "        X = df_7.iloc[:, comb]\n",
        "        lr.fit(X, y_7)\n",
        "        rss = np.sum((lr.predict(X) - y_7) ** 2)\n",
        "        \n",
        "        d = len(comb)\n",
        "        current_cp.append(1/n * (rss + 2 * d * sigma2))\n",
        "        current_bic.append(1/n * (rss + np.log(n) * d * sigma2))\n",
        "        current_adj_r2.append(1 - rss / (n - d - 1) * (n - 1) / tss)\n",
        "        \n",
        "    cp.append(min(current_cp))\n",
        "    bic.append(min(current_bic))\n",
        "    adj_r2.append(max(current_adj_r2))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexingError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexingError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-ce84b567949b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mcurrent_adj_r2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcomb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_7\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mrss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_7\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    871\u001b[0m                     \u001b[0;31m# AttributeError for IntervalTree get_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    874\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m             \u001b[0;31m# we by definition only have the 0th axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_valid_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1444\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_has_valid_tuple\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Too many indexers\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_key\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1354\u001b[0m             \u001b[0;31m# a tuple should already have been caught by this point\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m             \u001b[0;31m# so don't treat a tuple as a valid indexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Too many indexers\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_list_like_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m             \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexingError\u001b[0m: Too many indexers"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "CZgA_WCFFdx2",
        "outputId": "00782b86-7911-4567-9919-448f2f74ca87"
      },
      "source": [
        "# Best model is with one predictor\n",
        "plt.plot(range(10), cp)\n",
        "bic.append(min(current_bic))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-ce316a2a2fb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Best model is with one predictor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mbic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_bic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2761\u001b[0m     return gca().plot(\n\u001b[1;32m   2762\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2763\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1645\u001b[0m         \"\"\"\n\u001b[1;32m   1646\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1647\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1648\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    343\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (10,) and (0,)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiPomsBYFkY8"
      },
      "source": [
        "# Lasso\n",
        "X = df_7.iloc[:, :-1]\n",
        "X_stand = X / X.std()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_stand, y_7)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0B9Ou11gFxAg"
      },
      "source": [
        "alphas = np.linspace(0.001, 50, 100)\n",
        "errors =[]\n",
        "la = Lasso(alpha, max_iter=1000000000, tol = 0.000001)\n",
        "\n",
        "for alpha in alphas:\n",
        "  ls = Lasso(alpha=alpha)\n",
        "  ls.fit(X_train, y_train)\n",
        "  errors.append(np.mean((ls.predict(X_test) - y_test)**2))"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "9Bo6YsLEGJ6C",
        "outputId": "9b414cca-8d9d-49cd-86cd-f5476e382ab3"
      },
      "source": [
        "plt.plot(alphas, errors)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f4e9be04090>]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJyVaOyrGNnf",
        "outputId": "da3ed356-a781-4cc1-b12f-6bb258024a43"
      },
      "source": [
        "best_alpha = alphas[np.argmin(errors)]\n",
        "best_alpha"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5060404040404041"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_gePY-yGS9N",
        "outputId": "e85ed56d-e694-46f8-eae8-2bafd5cb295b"
      },
      "source": [
        "ls = Lasso(alpha=best_alpha, max_iter=100000, tol = 0.000001)\n",
        "ls.fit(X_stand, y_7)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Lasso(alpha=0.5060404040404041, copy_X=True, fit_intercept=True,\n",
              "      max_iter=100000, normalize=False, positive=False, precompute=False,\n",
              "      random_state=None, selection='cyclic', tol=1e-06, warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LptBHgRGcoi",
        "outputId": "1a4d1a04-f0d7-468a-aa6e-b6383b53acb7"
      },
      "source": [
        "# Coefficient doesn't resemble model at all. But these have been\n",
        "#scaled by their std. must divide by std\n",
        "ls.coef_"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  -0.        ,    0.        ,   -0.        ,    0.        ,\n",
              "         -0.        ,    0.        , -101.19532436,    0.        ,\n",
              "         -0.        ,    0.        ])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ej-_C-9zGimC",
        "outputId": "ba19b741-0452-4ee1-c76c-0a4d0f9725f8"
      },
      "source": [
        "# That's better - very close to actual value of -1\n",
        "ls.coef_ / x.std()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ -0.        ,   0.        ,  -0.        ,   0.        ,\n",
              "        -0.        ,   0.        , -98.08854626,   0.        ,\n",
              "        -0.        ,   0.        ])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CWdxeyZGqhC",
        "outputId": "41d21bae-c135-4e92-a357-d5f0eaa5d994"
      },
      "source": [
        "# Also look at the intercept\n",
        "ls.intercept_"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.1214870709935276"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pmdg_0S4GyFc"
      },
      "source": [
        "### **Question Nine**\n",
        "\n",
        "In this excercise, we will predict the number of college applications received using the other variables in the `College` dataset.\n",
        "\n",
        "A. Split the dataset into a training set and a test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9X5v0dLG8yN"
      },
      "source": [
        "college = pd.read_csv('https://raw.githubusercontent.com/emredjan/ISL-python/master/datasets/College.csv')"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "EkwzJ6SnHIJF",
        "outputId": "2dd9d87a-b995-461a-d56c-d77606f54e29"
      },
      "source": [
        "college.head()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Private</th>\n",
              "      <th>Apps</th>\n",
              "      <th>Accept</th>\n",
              "      <th>Enroll</th>\n",
              "      <th>Top10perc</th>\n",
              "      <th>Top25perc</th>\n",
              "      <th>F.Undergrad</th>\n",
              "      <th>P.Undergrad</th>\n",
              "      <th>Outstate</th>\n",
              "      <th>Room.Board</th>\n",
              "      <th>Books</th>\n",
              "      <th>Personal</th>\n",
              "      <th>PhD</th>\n",
              "      <th>Terminal</th>\n",
              "      <th>S.F.Ratio</th>\n",
              "      <th>perc.alumni</th>\n",
              "      <th>Expend</th>\n",
              "      <th>Grad.Rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Abilene Christian University</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1660</td>\n",
              "      <td>1232</td>\n",
              "      <td>721</td>\n",
              "      <td>23</td>\n",
              "      <td>52</td>\n",
              "      <td>2885</td>\n",
              "      <td>537</td>\n",
              "      <td>7440</td>\n",
              "      <td>3300</td>\n",
              "      <td>450</td>\n",
              "      <td>2200</td>\n",
              "      <td>70</td>\n",
              "      <td>78</td>\n",
              "      <td>18.1</td>\n",
              "      <td>12</td>\n",
              "      <td>7041</td>\n",
              "      <td>60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Adelphi University</td>\n",
              "      <td>Yes</td>\n",
              "      <td>2186</td>\n",
              "      <td>1924</td>\n",
              "      <td>512</td>\n",
              "      <td>16</td>\n",
              "      <td>29</td>\n",
              "      <td>2683</td>\n",
              "      <td>1227</td>\n",
              "      <td>12280</td>\n",
              "      <td>6450</td>\n",
              "      <td>750</td>\n",
              "      <td>1500</td>\n",
              "      <td>29</td>\n",
              "      <td>30</td>\n",
              "      <td>12.2</td>\n",
              "      <td>16</td>\n",
              "      <td>10527</td>\n",
              "      <td>56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Adrian College</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1428</td>\n",
              "      <td>1097</td>\n",
              "      <td>336</td>\n",
              "      <td>22</td>\n",
              "      <td>50</td>\n",
              "      <td>1036</td>\n",
              "      <td>99</td>\n",
              "      <td>11250</td>\n",
              "      <td>3750</td>\n",
              "      <td>400</td>\n",
              "      <td>1165</td>\n",
              "      <td>53</td>\n",
              "      <td>66</td>\n",
              "      <td>12.9</td>\n",
              "      <td>30</td>\n",
              "      <td>8735</td>\n",
              "      <td>54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Agnes Scott College</td>\n",
              "      <td>Yes</td>\n",
              "      <td>417</td>\n",
              "      <td>349</td>\n",
              "      <td>137</td>\n",
              "      <td>60</td>\n",
              "      <td>89</td>\n",
              "      <td>510</td>\n",
              "      <td>63</td>\n",
              "      <td>12960</td>\n",
              "      <td>5450</td>\n",
              "      <td>450</td>\n",
              "      <td>875</td>\n",
              "      <td>92</td>\n",
              "      <td>97</td>\n",
              "      <td>7.7</td>\n",
              "      <td>37</td>\n",
              "      <td>19016</td>\n",
              "      <td>59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Alaska Pacific University</td>\n",
              "      <td>Yes</td>\n",
              "      <td>193</td>\n",
              "      <td>146</td>\n",
              "      <td>55</td>\n",
              "      <td>16</td>\n",
              "      <td>44</td>\n",
              "      <td>249</td>\n",
              "      <td>869</td>\n",
              "      <td>7560</td>\n",
              "      <td>4120</td>\n",
              "      <td>800</td>\n",
              "      <td>1500</td>\n",
              "      <td>76</td>\n",
              "      <td>72</td>\n",
              "      <td>11.9</td>\n",
              "      <td>2</td>\n",
              "      <td>10922</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Unnamed: 0 Private  Apps  ...  perc.alumni  Expend  Grad.Rate\n",
              "0  Abilene Christian University     Yes  1660  ...           12    7041         60\n",
              "1            Adelphi University     Yes  2186  ...           16   10527         56\n",
              "2                Adrian College     Yes  1428  ...           30    8735         54\n",
              "3           Agnes Scott College     Yes   417  ...           37   19016         59\n",
              "4     Alaska Pacific University     Yes   193  ...            2   10922         15\n",
              "\n",
              "[5 rows x 19 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvsleBHiHMkH",
        "outputId": "1ac2e228-451f-4a59-b05c-fa152c998243"
      },
      "source": [
        "college['Private'].value_counts()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Yes    565\n",
              "No     212\n",
              "Name: Private, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RXd3mSSHRnZ"
      },
      "source": [
        "college['private_yes'] = (college['Private'] == 'Yes') *1"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHu6tJQqHX-s"
      },
      "source": [
        "X = college.iloc[:, 3:]"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3_ZnA7VHa1S"
      },
      "source": [
        "y = college['Apps']"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xm0BT5KHdkg"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2BXV6z-HjHK"
      },
      "source": [
        "B. Fit a linear model using least squares on the training set and report the test error obtained. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LyKWO77rHpJM",
        "outputId": "b59c1c1d-c358-4b36-e926-8d479a37c5a2"
      },
      "source": [
        "lr = LinearRegression()\n",
        "lr.fit(X_train, y_train)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcqXG8fLHu5n",
        "outputId": "e2c7bf1f-43c3-40b0-fadf-28a144c3d973"
      },
      "source": [
        "# Error\n",
        "np.mean((lr.predict(X_test) - y_test)**2)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "966943.0372505634"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXNkshZtH1pu"
      },
      "source": [
        "C. Fit a ridge regression model on the training set, with $\\lambda$ chosen by cross-validattion. Report the test error obtained. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_tUDd2hH9HQ"
      },
      "source": [
        "from sklearn.linear_model import RidgeCV"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VN-H-jf0ICpL"
      },
      "source": [
        "X_std = X.iloc[:, :-1].std()"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3wiiYUYIGB1"
      },
      "source": [
        "X_std['private_yes'] = 1"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4B-XLc0IIMzo",
        "outputId": "5f589981-b736-414a-f843-cb22358f53c5"
      },
      "source": [
        "X_std"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Accept         2451.113971\n",
              "Enroll          929.176190\n",
              "Top10perc        17.640364\n",
              "Top25perc        19.804778\n",
              "F.Undergrad    4850.420531\n",
              "P.Undergrad    1522.431887\n",
              "Outstate       4023.016484\n",
              "Room.Board     1096.696416\n",
              "Books           165.105360\n",
              "Personal        677.071454\n",
              "PhD              16.328155\n",
              "Terminal         14.722359\n",
              "S.F.Ratio         3.958349\n",
              "perc.alumni      12.391801\n",
              "Expend         5221.768440\n",
              "Grad.Rate        17.177710\n",
              "private_yes       1.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLJS_QaCIPCh"
      },
      "source": [
        "rcv = RidgeCV(alphas = np.linspace(0.01, 100, 1000), cv=10)\n",
        "rcv.fit(X / X_std, y)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}